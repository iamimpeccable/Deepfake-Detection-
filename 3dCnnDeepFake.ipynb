{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamimpeccable/Deepfake-Detection-/blob/main/3dCnnDeepFake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVcSjwYAdszf",
        "outputId": "59eec22b-dc24-499c-fdbc-a9b2f5a71070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_dst46', 'data_dst115', 'data_dst26', 'data_dst161', 'data_dst164']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace 'your_dataset.zip' with your uploaded zip file's name\n",
        "with zipfile.ZipFile('/content/PreprocessedForVideo-20241024T231730Z-001.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')  # Extract everything into /content/dataset\n",
        "\n",
        "# Ensure folders are extracted properly\n",
        "preprocessed_folder1 = '/content/dataset/PreprocessedForVideo/Deepfakes'\n",
        "preprocessed_folder2 = '/content/dataset/PreprocessedForVideo/original'\n",
        "#os.listdir(preprocessed_folder1)\n",
        "os.listdir(preprocessed_folder2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJanqxVQ497l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6ngQMezh3_2",
        "outputId": "c9e84b30-1a18-427a-bda0-9fcb9248ace8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['result26', 'result115', 'result46', 'result164', 'result161']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# List the contents of the PreprocessedForVideo folder\n",
        "os.listdir(preprocessed_folder1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_6V6pjvlWWZ",
        "outputId": "4d60a08d-8d27-40ae-a58a-d551f0f7fbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 4s/step - accuracy: 0.5036 - loss: 0.7231 - val_accuracy: 0.5553 - val_loss: 0.6884\n",
            "Epoch 2/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 4s/step - accuracy: 0.5324 - loss: 0.6914 - val_accuracy: 0.5580 - val_loss: 0.6895\n",
            "Epoch 3/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 4s/step - accuracy: 0.5187 - loss: 0.6927 - val_accuracy: 0.5553 - val_loss: 0.6900\n",
            "Epoch 4/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 4s/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.5553 - val_loss: 0.6864\n",
            "Epoch 5/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 4s/step - accuracy: 0.5199 - loss: 0.6932 - val_accuracy: 0.5274 - val_loss: 0.6884\n",
            "Epoch 6/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 4s/step - accuracy: 0.5348 - loss: 0.6880 - val_accuracy: 0.5606 - val_loss: 0.6832\n",
            "Epoch 7/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 4s/step - accuracy: 0.5403 - loss: 0.6816 - val_accuracy: 0.5633 - val_loss: 0.6584\n",
            "Epoch 8/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 4s/step - accuracy: 0.6278 - loss: 0.6206 - val_accuracy: 0.7951 - val_loss: 0.4025\n",
            "Epoch 9/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 4s/step - accuracy: 0.8061 - loss: 0.3800 - val_accuracy: 0.8553 - val_loss: 0.2894\n",
            "Epoch 10/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 4s/step - accuracy: 0.8682 - loss: 0.2516 - val_accuracy: 0.8158 - val_loss: 0.2830\n",
            "Epoch 11/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 4s/step - accuracy: 0.8697 - loss: 0.2574 - val_accuracy: 0.8616 - val_loss: 0.2589\n",
            "Epoch 12/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 4s/step - accuracy: 0.9040 - loss: 0.1972 - val_accuracy: 0.8940 - val_loss: 0.1951\n",
            "Epoch 13/13\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 4s/step - accuracy: 0.9202 - loss: 0.1634 - val_accuracy: 0.9030 - val_loss: 0.1823\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 917ms/step - accuracy: 0.8987 - loss: 0.1883\n",
            "Test Loss: 0.18231461942195892\n",
            "Test Accuracy: 0.9029649496078491\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 911ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.82      0.88       495\n",
            "           1       0.87      0.97      0.92       618\n",
            "\n",
            "    accuracy                           0.90      1113\n",
            "   macro avg       0.91      0.89      0.90      1113\n",
            "weighted avg       0.91      0.90      0.90      1113\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Initialize lists to store image data and labels\n",
        "image_data = []\n",
        "labels = []\n",
        "\n",
        "# Function to load images from subfolders\n",
        "def load_images_from_folder(folder, label):\n",
        "    for subfolder in os.listdir(folder):\n",
        "        subfolder_path = os.path.join(folder, subfolder)\n",
        "\n",
        "        # Check if it's a directory (subfolder containing images)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            for image_name in os.listdir(subfolder_path):\n",
        "                image_path = os.path.join(subfolder_path, image_name)\n",
        "\n",
        "                # Read the image\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is not None:\n",
        "                    # Resize the image to 64x64 pixels (you can adjust this as needed)\n",
        "                    image = cv2.resize(image, (64, 64))\n",
        "\n",
        "                    # Convert to array and append to image data\n",
        "                    image_data.append(img_to_array(image))\n",
        "                    labels.append(label)\n",
        "\n",
        "# Load images from both 'Deepfakes' and 'Original' folders\n",
        "deepfake_folder = preprocessed_folder1\n",
        "original_folder = preprocessed_folder2\n",
        "\n",
        "# Load images for Deepfakes (label 1) and Originals (label 0)\n",
        "load_images_from_folder(deepfake_folder, 1)\n",
        "load_images_from_folder(original_folder, 0)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "image_data = np.array(image_data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalize the images (scale pixel values between 0 and 1)\n",
        "image_data = image_data / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "labels = to_categorical(labels, num_classes=2)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define 3D CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "# **Change 1: Reshape the input to have more frames in the temporal dimension**\n",
        "# Reshape the input to add the temporal dimension, using at least 3 frames for 3D convolution\n",
        "model.add(layers.Reshape((64, 64, 3, 1), input_shape=(64, 64, 3)))\n",
        "# Reshape to (width, height, channels, frames) - This allows the Conv3D layer to work.\n",
        "# Please note you might need to adjust this based on the desired temporal depth\n",
        "\n",
        "# Add 3D Conv layer\n",
        "model.add(layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling3D((2, 2, 1)))\n",
        "\n",
        "# Add more Conv3D layers for better feature extraction\n",
        "model.add(layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling3D((2, 2, 1)))\n",
        "\n",
        "model.add(layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling3D((2, 2, 1)))\n",
        "\n",
        "# Flatten the output of the Conv3D layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(2, activation='softmax'))  # 2 classes: Deepfake (1) and Original (0)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=13, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert the predictions from one-hot encoding to labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred_labels))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YOz_a0NYq-Nbh1Yq8UfGRml2_Jgb_Mk7",
      "authorship_tag": "ABX9TyPUCwS8mxdp1iFiPW28mItx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}